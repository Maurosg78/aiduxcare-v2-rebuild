# üÜì LLMs Gratuitos para AiDuxCare - Gu√≠a Completa

## üéØ **OPCIONES GRATUITAS EVALUADAS**

### **ü•á OPCI√ìN 1: OLLAMA LOCAL** ‚≠ê **RECOMENDADA PARA CURSO**
```typescript
// Ventajas
- ‚úÖ 100% GRATUITO - Sin costos ni l√≠mites
- ‚úÖ Modelos m√©dicos: Llama-3.1 8B, Mistral 7B, CodeLlama
- ‚úÖ Privacidad total - Todo local
- ‚úÖ Perfecto para demos acad√©micas
- ‚úÖ API REST compatible con OpenAI
- ‚úÖ Instalaci√≥n simple en Mac/Windows/Linux

// Desventajas
- ‚ùå Requiere 8GB+ RAM para modelos buenos
- ‚ùå Procesamiento m√°s lento que APIs cloud
```

### **ü•à OPCI√ìN 2: HUGGING FACE INFERENCE API**
```typescript
// Ventajas
- ‚úÖ Tier gratuito: 30,000 requests/mes
- ‚úÖ Modelos m√©dicos especializados
- ‚úÖ API similar a OpenAI
- ‚úÖ No requiere hardware potente

// Desventajas
- ‚ùå L√≠mites de uso mensual
- ‚ùå Latencia variable
```

### **ü•â OPCI√ìN 3: GROQ API**
```typescript
// Ventajas
- ‚úÖ SUPER R√ÅPIDO (5-10x m√°s que OpenAI)
- ‚úÖ Tier gratuito generoso
- ‚úÖ API compatible

// Desventajas
- ‚ùå Modelos limitados
- ‚ùå Menos especializaci√≥n m√©dica
```

---

## üöÄ **IMPLEMENTACI√ìN OLLAMA - PASO A PASO**

### **INSTALACI√ìN OLLAMA (5 minutos)**

```bash
# macOS
curl -fsSL https://ollama.ai/install.sh | sh

# Windows: Descargar desde https://ollama.ai/download
# Linux
curl -fsSL https://ollama.ai/install.sh | sh

# Verificar instalaci√≥n
ollama --version
```

### **DESCARGAR MODELOS M√âDICOS**

```bash
# Modelo principal para fisioterapia (4GB)
ollama pull llama3.2:3b

# Modelo m√°s potente si tienes >8GB RAM (7GB)
ollama pull mistral:7b

# Modelo especializado en c√≥digo/estructura (4GB)
ollama pull codellama:7b

# Verificar modelos instalados
ollama list
```

### **INICIAR SERVIDOR OLLAMA**

```bash
# Iniciar servicio Ollama (puerto 11434)
ollama serve

# En otra terminal, probar conexi√≥n
curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2:3b",
  "prompt": "Explica qu√© es fisioterapia",
  "stream": false
}'
```

---

## üíª **C√ìDIGO PARA AIDUXCARE CON OLLAMA**

### **1. Configuraci√≥n Ollama Client**

```typescript
// src/lib/ollama.ts
export class OllamaClient {
  private baseUrl: string;
  private model: string;

  constructor(baseUrl = 'http://localhost:11434', model = 'llama3.2:3b') {
    this.baseUrl = baseUrl;
    this.model = model;
  }

  async generateCompletion(prompt: string): Promise<{
    response: string;
    tokens: number;
    duration: number;
  }> {
    const response = await fetch(`${this.baseUrl}/api/generate`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: this.model,
        prompt,
        stream: false,
        options: {
          temperature: 0.3,
          top_p: 0.9,
          max_tokens: 2000
        }
      })
    });

    const data = await response.json();
    
    return {
      response: data.response,
      tokens: data.eval_count || 0,
      duration: data.total_duration || 0
    };
  }

  async chatCompletion(messages: Array<{role: string, content: string}>): Promise<string> {
    // Convertir mensajes a prompt simple para Ollama
    const prompt = messages
      .map(m => `${m.role === 'user' ? 'Usuario' : 'Asistente'}: ${m.content}`)
      .join('\n') + '\nAsistente:';

    const result = await this.generateCompletion(prompt);
    return result.response;
  }
}

export const ollamaClient = new OllamaClient();
```

### **2. Servicio NLP con Ollama**

```typescript
// src/services/nlpServiceOllama.ts
import { ollamaClient } from '../lib/ollama';
import { ClinicalEntity, SOAPNotes } from '../types/nlp';

export class NLPServiceOllama {
  
  static async extractClinicalEntities(transcript: string): Promise<ClinicalEntity[]> {
    const prompt = `
TAREA: Analiza esta transcripci√≥n de fisioterapia y extrae entidades cl√≠nicas.

TRANSCRIPCI√ìN:
"${transcript}"

INSTRUCCIONES:
- Identifica s√≠ntomas, tratamientos, diagn√≥sticos, objetivos
- Responde SOLO con JSON v√°lido
- Formato: [{"type": "symptom", "text": "dolor rodilla", "confidence": 0.9}]

TIPOS PERMITIDOS: symptom, treatment, diagnosis, objective, plan, exercise

JSON:`;

    try {
      const result = await ollamaClient.generateCompletion(prompt);
      
      // Limpiar respuesta y extraer JSON
      const jsonMatch = result.response.match(/\[.*\]/s);
      if (jsonMatch) {
        return JSON.parse(jsonMatch[0]);
      }
      
      return [];
    } catch (error) {
      console.error('Error extracting entities:', error);
      return [];
    }
  }

  static async generateSOAPNotes(transcript: string, entities: ClinicalEntity[]): Promise<SOAPNotes> {
    const prompt = `
TAREA: Genera nota SOAP profesional para fisioterapia.

TRANSCRIPCI√ìN:
"${transcript}"

ENTIDADES IDENTIFICADAS:
${JSON.stringify(entities, null, 2)}

INSTRUCCIONES:
- Escribe como fisioterapeuta profesional
- Usa terminolog√≠a m√©dica apropiada
- Responde SOLO con JSON v√°lido
- Sigue formato SOAP estricto

FORMATO JSON:
{
  "subjective": "Lo que reporta el paciente...",
  "objective": "Observaciones del fisioterapeuta...",
  "assessment": "An√°lisis profesional...",
  "plan": "Plan de tratamiento..."
}

JSON:`;

    try {
      const result = await ollamaClient.generateCompletion(prompt);
      
      // Extraer JSON de la respuesta
      const jsonMatch = result.response.match(/\{.*\}/s);
      if (jsonMatch) {
        const soapData = JSON.parse(jsonMatch[0]);
        return {
          ...soapData,
          generated_at: new Date(),
          confidence_score: 0.85 // Estimado para Ollama
        };
      }
      
      // Fallback si no se puede parsear
      return {
        subjective: "No se pudo extraer informaci√≥n subjetiva",
        objective: "No se pudo extraer informaci√≥n objetiva", 
        assessment: "Requiere revisi√≥n manual",
        plan: "Pendiente de evaluaci√≥n",
        generated_at: new Date(),
        confidence_score: 0.3
      };
      
    } catch (error) {
      console.error('Error generating SOAP:', error);
      throw new Error('Failed to generate SOAP notes');
    }
  }
}
```

### **3. Configuraci√≥n de Variables de Entorno**

```bash
# .env.local
# Configuraci√≥n Ollama (GRATIS)
VITE_LLM_PROVIDER=ollama
VITE_OLLAMA_URL=http://localhost:11434
VITE_OLLAMA_MODEL=llama3.2:3b

# Backup: Hugging Face (Gratuito con l√≠mites)
VITE_HUGGINGFACE_API_KEY=hf_tu_key_gratuita
VITE_HF_MODEL=microsoft/DialoGPT-medium
```

### **4. Audio Processing con Ollama**

```typescript
// src/services/audioProcessingServiceOllama.ts
import { NLPServiceOllama } from './nlpServiceOllama';
import { ClinicalEntity, SOAPNotes } from '../types/nlp';

export class AudioProcessingServiceOllama {
  
  static async processAudioSession(audioFile: File): Promise<{
    transcript: string;
    entities: ClinicalEntity[];
    soapNotes: SOAPNotes;
    processingTime: number;
  }> {
    
    const startTime = Date.now();
    
    // 1. Speech-to-Text (Web Speech API - GRATIS)
    const transcript = await this.speechToTextFree(audioFile);
    
    // 2. Extracci√≥n de entidades con Ollama (GRATIS)
    const entities = await NLPServiceOllama.extractClinicalEntities(transcript);
    
    // 3. Generaci√≥n SOAP con Ollama (GRATIS)
    const soapNotes = await NLPServiceOllama.generateSOAPNotes(transcript, entities);
    
    const processingTime = Date.now() - startTime;
    
    return {
      transcript,
      entities,
      soapNotes,
      processingTime
    };
  }

  private static async speechToTextFree(audioFile: File): Promise<string> {
    // Simulaci√≥n para MVP - En producci√≥n usar Web Speech API
    const simulatedTranscripts = [
      "El paciente Juan reporta dolor en rodilla derecha desde hace 3 d√≠as. Observo inflamaci√≥n leve. Aplicamos terapia manual y ejercicios de movilidad. Buena respuesta al tratamiento. Plan: ejercicios en casa y control en una semana.",
      "Paciente Mar√≠a con dolor lumbar cr√≥nico. Evaluaci√≥n muestra rigidez muscular. Tratamiento con masaje terap√©utico y estiramientos. Mejora parcial. Continuaremos con fisioterapia dos veces por semana.",
      "Sesi√≥n de seguimiento para rehabilitaci√≥n de hombro. Paciente muestra progreso en rango de movimiento. Ejercicios de fortalecimiento funcionando bien. Reducir frecuencia a una vez por semana."
    ];
    
    // Simular procesamiento
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    return simulatedTranscripts[Math.floor(Math.random() * simulatedTranscripts.length)];
  }
}
```

---

## üß™ **SCRIPT DE TESTING OLLAMA**

```typescript
// src/scripts/testOllama.ts
import { NLPServiceOllama } from '../services/nlpServiceOllama';

const testTranscript = `
El paciente Carlos lleg√≥ reportando dolor intenso en la zona lumbar. 
Menciona que comenz√≥ despu√©s de levantar una caja pesada en el trabajo. 
Durante la evaluaci√≥n observ√© tensi√≥n muscular significativa en el √°rea paravertebral. 
Limitaci√≥n notable en la flexi√≥n anterior del tronco.
Aplicamos masaje terap√©utico profundo y t√©cnicas de liberaci√≥n miofascial.
El paciente report√≥ alivio inmediato del 60% del dolor.
Plan: continuar con sesiones de fisioterapia tres veces por semana,
ejercicios de fortalecimiento del core en casa, y aplicaci√≥n de calor local.
`;

async function testOllamaPipeline() {
  try {
    console.log('üß™ Testing Ollama LLM Integration...');
    console.log('üìù Transcript:', testTranscript.substring(0, 100) + '...');
    
    // Test 1: Extracci√≥n de entidades
    console.log('\nüîç Extracting clinical entities...');
    const entities = await NLPServiceOllama.extractClinicalEntities(testTranscript);
    console.log('‚úÖ Entities extracted:', entities.length);
    entities.forEach(entity => {
      console.log(`  - ${entity.type}: "${entity.text}" (${entity.confidence})`);
    });
    
    // Test 2: Generaci√≥n SOAP
    console.log('\nüìã Generating SOAP notes...');
    const soapNotes = await NLPServiceOllama.generateSOAPNotes(testTranscript, entities);
    console.log('‚úÖ SOAP Notes generated:');
    console.log('  S:', soapNotes.subjective.substring(0, 80) + '...');
    console.log('  O:', soapNotes.objective.substring(0, 80) + '...');
    console.log('  A:', soapNotes.assessment.substring(0, 80) + '...');
    console.log('  P:', soapNotes.plan.substring(0, 80) + '...');
    
    console.log('\nüéâ Ollama Integration successful! üÜì');
    console.log('üí∞ Costo total: $0.00 (GRATIS)');
    
  } catch (error) {
    console.error('‚ùå Ollama Integration failed:', error);
    console.log('\nüîß Troubleshooting:');
    console.log('1. ¬øEst√° Ollama corriendo? ‚Üí ollama serve');
    console.log('2. ¬øModelo descargado? ‚Üí ollama pull llama3.2:3b');
    console.log('3. ¬øPuerto correcto? ‚Üí curl http://localhost:11434');
  }
}

// Ejecutar test
testOllamaPipeline();
```

---

## üìã **COMANDOS DE INSTALACI√ìN R√ÅPIDA**

```bash
# 1. Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# 2. Descargar modelo principal
ollama pull llama3.2:3b

# 3. Iniciar servidor (en terminal separada)
ollama serve

# 4. Crear archivos en AiDuxCare
touch src/lib/ollama.ts
touch src/services/nlpServiceOllama.ts
touch src/services/audioProcessingServiceOllama.ts
touch src/scripts/testOllama.ts

# 5. Actualizar .env.local
echo "VITE_LLM_PROVIDER=ollama" >> .env.local
echo "VITE_OLLAMA_URL=http://localhost:11434" >> .env.local
echo "VITE_OLLAMA_MODEL=llama3.2:3b" >> .env.local

# 6. Test de funcionamiento
npm run build
```

---

## üéØ **COMPARACI√ìN: COSTOS PROYECTADOS**

| Proveedor | Costo por 1000 tokens | Costo 100 transcripciones | L√≠mites |
|-----------|----------------------|---------------------------|---------|
| **OpenAI GPT-3.5** | $0.002 | ~$5-10 | Sin l√≠mite (pagando) |
| **Ollama Local** | **$0.00** | **$0.00** | Solo hardware |
| **Hugging Face** | $0.00 | $0.00 | 30K requests/mes |
| **Groq** | $0.00 | $0.00 | L√≠mites diarios |

---

## ‚úÖ **RECOMENDACI√ìN FINAL PARA EL CURSO**

**Mauricio, mi recomendaci√≥n oficial como Implementador Jefe:**

### **USAR OLLAMA PORQUE:**
1. ‚úÖ **100% gratuito** - Perfecto para proyecto acad√©mico
2. ‚úÖ **Funciona offline** - Ideal para demos sin internet
3. ‚úÖ **Control total** - No dependes de APIs externas
4. ‚úÖ **Impresiona al profesorado** - Demuestra conocimiento t√©cnico avanzado
5. ‚úÖ **Escalable** - Puedes cambiar modelos f√°cilmente

### **PLAN DE IMPLEMENTACI√ìN:**
1. **Instalar Ollama** hoy mismo (5 minutos)
2. **Descargar modelo llama3.2:3b** (10 minutos)
3. **Implementar c√≥digo** que te proporciono (30 minutos)
4. **Probar pipeline completo** (15 minutos)

**¬øListo para implementar la soluci√≥n 100% gratuita? üöÄ** 