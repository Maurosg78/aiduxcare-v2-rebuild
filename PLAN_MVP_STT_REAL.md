# üé§ PLAN MVP - Implementaci√≥n STT Real (COSTO $0)

## üéØ **OBJETIVO**
Reemplazar el STT simulado con **procesamiento de audio real** usando **Web Speech API** del navegador (GRATUITO) + **Ollama** (GRATUITO).

---

## üìä **AN√ÅLISIS DE COSTOS ACTUALIZADO**

### **üí∞ COSTO TOTAL: $0.00 USD**

#### **STT: Web Speech API (Navegador)**
- **Costo**: $0.00 (Gratis total)
- **L√≠mites**: Solo funciona online, depende de Chrome/Edge
- **Precisi√≥n**: 85-95% en espa√±ol (Google Speech Engine)
- **Ventajas**: Tiempo real, sin env√≠o de archivos, privacidad

#### **NLP: Ollama Local (Ya implementado)**  
- **Costo**: $0.00 (Gratis total)
- **Modelos**: llama3.2:3b, mistral:7b
- **L√≠mites**: Solo recursos locales (CPU/RAM)
- **Ventajas**: 100% privado, sin l√≠mites de API

#### **Almacenamiento: Supabase Free Tier**
- **Costo**: $0.00 (hasta 500MB DB + 1GB Storage)
- **L√≠mites**: 50,000 requests/mes
- **Ventajas**: PostgreSQL completo, RLS, Functions

### **ROI vs Competencia:**
- **Nuance Dragon Medical**: $500-1500/mes ‚Üí Ahorro: **100%**
- **3M Speech Recognition**: $200-800/mes ‚Üí Ahorro: **100%**  
- **OpenAI Whisper**: $90-120/mes ‚Üí Ahorro: **100%**

---

## üèóÔ∏è **IMPLEMENTACI√ìN T√âCNICA**

### **Fase 1: WebSpeechSTTService (Gratis) - Semana 1**

```typescript
// src/services/WebSpeechSTTService.ts
export class WebSpeechSTTService {
  private recognition: SpeechRecognition | null = null;
  private isSupported: boolean = false;
  private currentStream: MediaStream | null = null;
  
  constructor() {
    // Verificar soporte del navegador
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    this.isSupported = !!SpeechRecognition;
    
    if (this.isSupported) {
      this.recognition = new SpeechRecognition();
      this.setupRecognition();
    }
  }
  
  private setupRecognition(): void {
    if (!this.recognition) return;
    
    // Configuraci√≥n optimizada para espa√±ol m√©dico
    this.recognition.continuous = true;
    this.recognition.interimResults = true;
    this.recognition.lang = 'es-ES'; // Espa√±ol de Espa√±a (mejor para t√©rminos m√©dicos)
    this.recognition.maxAlternatives = 1;
    
    // Eventos principales
    this.recognition.onstart = () => {
      console.log('üéôÔ∏è Reconocimiento de voz iniciado');
      AuditLogger.log('stt.webspeech.started', { provider: 'browser_native' });
    };
    
    this.recognition.onend = () => {
      console.log('üéôÔ∏è Reconocimiento de voz finalizado');
      AuditLogger.log('stt.webspeech.ended', { provider: 'browser_native' });
    };
    
    this.recognition.onerror = (event) => {
      console.error('‚ùå Error en reconocimiento:', event.error);
      AuditLogger.log('stt.webspeech.error', { 
        error: event.error,
        provider: 'browser_native' 
      });
    };
  }
  
  async startRealtimeTranscription(
    onResult: (segment: TranscriptionSegment) => void,
    language: 'es' | 'en' = 'es'
  ): Promise<void> {
    
    if (!this.isSupported || !this.recognition) {
      throw new Error('Web Speech API no soportada en este navegador');
    }
    
    // Configurar idioma
    this.recognition.lang = language === 'es' ? 'es-ES' : 'en-US';
    
    // Handler de resultados en tiempo real
    this.recognition.onresult = (event: SpeechRecognitionEvent) => {
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i];
        const transcript = result[0].transcript;
        const confidence = result[0].confidence || 0.8;
        
        const segment: TranscriptionSegment = {
          id: `webspeech_${Date.now()}_${i}`,
          timestamp: new Date().toISOString(),
          content: transcript.trim(),
          confidence: this.mapConfidenceLevel(confidence),
          actor: this.detectActor(transcript),
          approved: false,
          edited: false,
          is_final: result.isFinal
        };
        
        onResult(segment);
      }
    };
    
    // Solicitar permisos de micr√≥fono
    await this.requestMicrophoneAccess();
    
    // Iniciar reconocimiento
    this.recognition.start();
  }
  
  async stopTranscription(): Promise<void> {
    if (this.recognition) {
      this.recognition.stop();
    }
    
    if (this.currentStream) {
      this.currentStream.getTracks().forEach(track => track.stop());
      this.currentStream = null;
    }
  }
  
  private async requestMicrophoneAccess(): Promise<void> {
    try {
      this.currentStream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 16000
        }
      });
    } catch (error) {
      throw new Error('Acceso al micr√≥fono denegado');
    }
  }
  
  private detectActor(text: string): TranscriptionActor {
    const professionalKeywords = [
      'vamos a', 'observe', 'eval√∫o', 'recomiendo', 'aplicamos', 
      'necesita', 'veo que', 'trataremos', 'diagnosis', 'procedimiento'
    ];
    
    const patientKeywords = [
      'me duele', 'siento', 'tengo', 'no puedo', 'cuando',
      'desde hace', 'me pasa', 'me molesta', 'dolor'
    ];
    
    const lowerText = text.toLowerCase();
    
    const profScore = professionalKeywords.reduce((score, keyword) => 
      lowerText.includes(keyword) ? score + 1 : score, 0
    );
    
    const patientScore = patientKeywords.reduce((score, keyword) => 
      lowerText.includes(keyword) ? score + 1 : score, 0
    );
    
    return profScore > patientScore ? 'profesional' : 'paciente';
  }
  
  private mapConfidenceLevel(confidence: number): TranscriptionConfidence {
    if (confidence >= 0.8) return 'entendido';
    if (confidence >= 0.5) return 'poco_claro';
    return 'no_reconocido';
  }
  
  // M√©todo est√°tico para verificar soporte
  static isSupported(): boolean {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    return !!SpeechRecognition;
  }
  
  // Fallback para navegadores no soportados
  static createFallbackMessage(): string {
    return `
      ‚ö†Ô∏è Tu navegador no soporta Web Speech API.
      Por favor usa Chrome, Edge o Firefox para STT en tiempo real.
      Como alternativa, puedes cargar archivos de audio.
    `;
  }
}
```

### **Fase 2: AudioCaptureServiceReal (Gratis) - Semana 1**

```typescript
// src/services/AudioCaptureServiceReal.ts
import { WebSpeechSTTService } from './WebSpeechSTTService';

export class AudioCaptureServiceReal {
  private sttService: WebSpeechSTTService;
  private segments: TranscriptionSegment[] = [];
  private isRecording: boolean = false;
  
  constructor() {
    this.sttService = new WebSpeechSTTService();
  }
  
  async startCapture(language: 'es' | 'en' = 'es'): Promise<void> {
    if (this.isRecording) return;
    
    this.segments = [];
    this.isRecording = true;
    
    await this.sttService.startRealtimeTranscription(
      (segment) => this.handleNewSegment(segment),
      language
    );
  }
  
  async stopCapture(): Promise<TranscriptionSegment[]> {
    if (!this.isRecording) return this.segments;
    
    await this.sttService.stopTranscription();
    this.isRecording = false;
    
    // Filtrar solo segmentos finales para resultados
    const finalSegments = this.segments.filter(s => s.is_final);
    
    return finalSegments;
  }
  
  private handleNewSegment(segment: TranscriptionSegment): void {
    // Actualizar o agregar segmento
    const existingIndex = this.segments.findIndex(s => s.id === segment.id);
    
    if (existingIndex !== -1) {
      this.segments[existingIndex] = segment;
    } else {
      this.segments.push(segment);
    }
    
    // Emit event para UI en tiempo real
    if (typeof window !== 'undefined') {
      window.dispatchEvent(new CustomEvent('transcription-update', {
        detail: { segment, allSegments: this.segments }
      }));
    }
  }
  
  getCurrentTranscription(): TranscriptionSegment[] {
    return [...this.segments];
  }
  
  isSupported(): boolean {
    return WebSpeechSTTService.isSupported();
  }
}
```

### **Fase 3: Integraci√≥n Pipeline Gratuito - Semana 2**

```typescript
// Actualizaci√≥n en AudioProcessingServiceProfessional.ts
private static async speechToTextReal(
  language: 'es' | 'en',
  processingId: string,
  onProgress?: (stage: string) => void
): Promise<TranscriptionSegment[]> {
  
  onProgress?.('Iniciando captura de audio...');
  
  try {
    const captureService = new AudioCaptureServiceReal();
    
    if (!captureService.isSupported()) {
      console.warn('Web Speech API no soportada, usando simulaci√≥n');
      return this.speechToTextSimulated(language, processingId);
    }
    
    // Mostrar instrucciones al usuario
    onProgress?.('Habla ahora - presiona Detener cuando termines');
    
    // En implementaci√≥n real, esto ser√≠a manejado por el UI
    // Por ahora simulamos una grabaci√≥n de 30 segundos
    await captureService.startCapture(language);
    
    // Simular tiempo de grabaci√≥n para demo
    await new Promise(resolve => setTimeout(resolve, 30000));
    
    const segments = await captureService.stopCapture();
    
    // Audit logging
    AuditLogger.log('stt.webspeech.completed', {
      processingId,
      segmentsCount: segments.length,
      language,
      provider: 'web_speech_api',
      cost_usd: 0.0 // ¬°GRATIS!
    });
    
    return segments;
    
  } catch (error) {
    console.warn('Web Speech API fall√≥, usando simulaci√≥n:', error);
    return this.speechToTextSimulated(language, processingId);
  }
}

// M√©todo helper para STT simulado mejorado
private static async speechToTextSimulated(
  language: 'es' | 'en',
  processingId: string
): Promise<TranscriptionSegment[]> {
  
  const simulatedTranscripts = language === 'es' ? 
    this.getSimulatedSpanishTranscripts() : 
    this.getSimulatedEnglishTranscripts();
  
  // Simular procesamiento real
  await new Promise(resolve => setTimeout(resolve, 2000));
  
  return simulatedTranscripts.map((content, index) => ({
    id: `${processingId}-sim-${index + 1}`,
    timestamp: new Date(Date.now() + index * 2000).toISOString(),
    actor: this.detectActor(content),
    content,
    confidence: this.calculateConfidence(content),
    approved: false,
    edited: false,
    is_final: true
  }));
}

private static getSimulatedSpanishTranscripts(): string[] {
  return [
    "Buenos d√≠as doctor, vengo porque tengo dolor en la rodilla derecha desde hace una semana",
    "¬øEl dolor es constante o solo cuando camina?",
    "Principalmente cuando camino o subo escaleras, en reposo est√° mejor",
    "Voy a examinar la rodilla, ¬øpuede flexionar la pierna?",
    "S√≠, pero siento dolor cuando la doblo completamente",
    "Observo una leve inflamaci√≥n. Vamos a aplicar terapia manual y ejercicios espec√≠ficos",
    "¬øCu√°nto tiempo tomar√° la recuperaci√≥n?",
    "Con el tratamiento adecuado, deber√≠as sentir mejora en 2-3 semanas"
  ];
}
```

---

## üóÑÔ∏è **BLOQUE 2: PERSISTENCIA REAL (Ya implementado)**

El schema de Supabase se mantiene igual, pero ahora **100% gratuito**:

```sql
-- Ya implementado en fases anteriores
-- Usar Supabase Free Tier: 500MB DB + 1GB Storage
-- 50,000 requests/mes (suficiente para MVP)
```

---

## üì± **ACTUALIZACI√ìN UX PARA AUDIO REAL GRATUITO**

```typescript
// src/components/professional/RealAudioProcessorFree.tsx
export const RealAudioProcessorFree: React.FC = () => {
  const [isRecording, setIsRecording] = useState(false);
  const [isSupported, setIsSupported] = useState(true);
  const [currentTranscript, setCurrentTranscript] = useState('');
  const [processingResult, setProcessingResult] = useState<AudioProcessingResult | null>(null);
  
  const captureService = useRef(new AudioCaptureServiceReal());
  const dataService = useRef(new ClinicalDataService());
  
  useEffect(() => {
    // Verificar soporte del navegador
    if (!WebSpeechSTTService.isSupported()) {
      setIsSupported(false);
    }
    
    // Listener para transcripci√≥n en tiempo real
    const handleTranscriptionUpdate = (event: CustomEvent) => {
      const { segment } = event.detail;
      if (!segment.is_final) {
        setCurrentTranscript(segment.content);
      }
    };
    
    window.addEventListener('transcription-update', handleTranscriptionUpdate);
    
    return () => {
      window.removeEventListener('transcription-update', handleTranscriptionUpdate);
    };
  }, []);
  
  const handleStartRecording = async () => {
    try {
      await captureService.current.startCapture('es');
      setIsRecording(true);
      setCurrentTranscript('');
    } catch (error) {
      console.error('Error iniciando grabaci√≥n:', error);
      alert('Error al acceder al micr√≥fono. Aseg√∫rate de dar permisos.');
    }
  };
  
  const handleStopRecording = async () => {
    try {
      const segments = await captureService.current.stopCapture();
      setIsRecording(false);
      setCurrentTranscript('');
      
      // Procesar con Ollama (tambi√©n gratis)
      await processWithOllama(segments);
    } catch (error) {
      console.error('Error deteniendo grabaci√≥n:', error);
    }
  };
  
  const processWithOllama = async (segments: TranscriptionSegment[]) => {
    try {
      // Crear sesi√≥n en Supabase
      const { sessionId } = await dataService.current.createClinicalSession({
        patientId: 'current-patient',
        visitId: `visit_${Date.now()}`,
        sessionType: 'follow_up'
      });
      
      // Procesar con pipeline gratuito completo
      const fullTranscript = segments.map(s => `${s.actor}: ${s.content}`).join('\n');
      
      // NLP con Ollama (GRATIS)
      const nlpResult = await NLPServiceOllama.processTranscript(fullTranscript);
      
      // Guardar resultados
      await dataService.current.saveTranscriptionSegments(sessionId, segments);
      await dataService.current.saveClinicalEntities(sessionId, nlpResult.entities);
      await dataService.current.saveSOAPNotes(sessionId, nlpResult.soapNotes);
      
      setProcessingResult({
        transcription: segments,
        entities: nlpResult.entities,
        soapNotes: nlpResult.soapNotes,
        metrics: {
          ...nlpResult.metrics,
          stt_cost_usd: 0.0, // ¬°Web Speech API es gratis!
          nlp_cost_usd: 0.0, // ¬°Ollama es gratis!
          total_cost_usd: 0.0 // ¬°TODO GRATIS!
        }
      });
      
    } catch (error) {
      console.error('Error procesando audio:', error);
    }
  };
  
  if (!isSupported) {
    return (
      <div className="real-audio-processor">
        <div className="browser-not-supported">
          <h3>‚ö†Ô∏è Navegador No Compatible</h3>
          <p>{WebSpeechSTTService.createFallbackMessage()}</p>
          <div className="supported-browsers">
            <h4>Navegadores Compatibles:</h4>
            <ul>
              <li>‚úÖ Google Chrome (recomendado)</li>
              <li>‚úÖ Microsoft Edge</li>
              <li>‚ö†Ô∏è Firefox (soporte limitado)</li>
              <li>‚ùå Safari (no soportado)</li>
            </ul>
          </div>
        </div>
      </div>
    );
  }
  
  return (
    <div className="real-audio-processor">
      <div className="audio-controls">
        <div className="cost-indicator">
          <span className="cost-badge">üí∞ COSTO: $0.00</span>
          <span className="tech-stack">Web Speech API + Ollama + Supabase Free</span>
        </div>
        
        {!isRecording ? (
          <button 
            onClick={handleStartRecording} 
            className="btn-record"
            disabled={!isSupported}
          >
            üé§ Iniciar Grabaci√≥n (GRATIS)
          </button>
        ) : (
          <div className="recording-active">
            <button onClick={handleStopRecording} className="btn-stop">
              ‚èπÔ∏è Detener y Procesar
            </button>
            <div className="live-transcript">
              <h4>Transcripci√≥n en vivo:</h4>
              <p className="transcript-text">{currentTranscript}</p>
              <div className="recording-indicator">
                <div className="pulse-dot"></div>
                Grabando...
              </div>
            </div>
          </div>
        )}
      </div>
      
      {processingResult && (
        <div className="processing-results">
          <div className="cost-summary">
            <h3>üìä Resumen de Costos</h3>
            <div className="cost-breakdown">
              <div className="cost-item">
                <span>STT (Web Speech API):</span>
                <span className="cost-value">$0.00</span>
              </div>
              <div className="cost-item">
                <span>NLP (Ollama Local):</span>
                <span className="cost-value">$0.00</span>
              </div>
              <div className="cost-item">
                <span>Storage (Supabase Free):</span>
                <span className="cost-value">$0.00</span>
              </div>
              <div className="cost-total">
                <span>TOTAL:</span>
                <span className="cost-value total">$0.00</span>
              </div>
            </div>
          </div>
          
          <ClinicalResultsPanel 
            entities={processingResult.entities}
            soapNotes={processingResult.soapNotes}
            transcription={processingResult.transcription}
          />
        </div>
      )}
    </div>
  );
};
```

---

## ‚úÖ **ENTREGABLES SEMANA 1-2 (COSTO $0)**

### **Semana 1:**
1. ‚úÖ **WebSpeechSTTService** - STT gratuito navegador
2. ‚úÖ **AudioCaptureServiceReal** - Captura en tiempo real  
3. ‚úÖ **Detecci√≥n de compatibilidad** navegadores
4. ‚úÖ **Fallbacks** para navegadores no soportados

### **Semana 2:**
1. ‚úÖ **Integraci√≥n pipeline** Web Speech + Ollama
2. ‚úÖ **RealAudioProcessorFree** componente UI
3. ‚úÖ **Transcripci√≥n tiempo real** con feedback visual
4. ‚úÖ **Tests funcionales** cross-browser
5. ‚úÖ **MVP 100% gratuito** sin APIs de pago

---

## üéØ **CRITERIOS DE √âXITO MVP (COSTO $0)**

### **Funcionalidad M√≠nima Viable:**
- ‚úÖ **STT real**: Web Speech API en Chrome/Edge
- ‚úÖ **Precisi√≥n**: >85% espa√±ol m√©dico  
- ‚úÖ **Tiempo real**: Transcripci√≥n en vivo
- ‚úÖ **Persistencia**: Supabase Free Tier
- ‚úÖ **NLP**: Ollama local para entidades/SOAP
- ‚úÖ **Costo total**: $0.00 USD

### **M√©tricas de Validaci√≥n:**
- **Tiempo total proceso**: <3 minutos (STT ‚Üí insights)
- **Costo por sesi√≥n**: $0.00 USD (¬°GRATIS!)
- **Precisi√≥n cl√≠nica**: >80% entidades correctas  
- **Compatibilidad**: Chrome 90+, Edge 90+
- **Satisfacci√≥n usuario**: ‚â•7/10 usabilidad

### **Limitaciones Conocidas:**
- **Navegador**: Solo Chrome/Edge (90% usuarios)
- **Conexi√≥n**: Requiere internet para STT
- **Privacidad**: Audio procesado por Google (est√°ndar mercado)
- **Idioma**: Optimizado para espa√±ol, ingl√©s b√°sico

---

## üöÄ **VENTAJAS DEL ENFOQUE GRATUITO**

### **Econ√≥micas:**
- **Costo operacional**: $0.00 mensual
- **Escalabilidad**: Sin l√≠mites de API paid
- **ROI inmediato**: 100% ahorro vs competencia

### **T√©cnicas:**
- **Latencia baja**: STT en tiempo real
- **No upload**: No env√≠o archivos audio  
- **Pipeline integrado**: Web Speech ‚Üí Ollama ‚Üí Supabase
- **Compatibilidad**: Navegadores modernos (90% mercado)

### **Estrat√©gicas:**
- **Independencia**: Sin vendor lock-in APIs
- **Privacidad**: Procesamiento local Ollama
- **Sostenibilidad**: Modelo viable largo plazo

---

**üöÄ MAURICIO: PLAN ACTUALIZADO - 100% GRATIS CON WEB SPEECH API + OLLAMA + SUPABASE FREE**

**¬øAPROBAMOS ESTE NUEVO ENFOQUE SIN COSTOS DE IA?** 